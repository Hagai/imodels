{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook shows some examples of fitting different models to classification/regression datasets. We start by loading some classifiers / regressors from `imodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree, DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# installable with: `pip install imodels`\n",
    "import imodels\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start by loading some data in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes (270, 15) (270,) nunique 2\n",
      "best params {'est': LogisticRegression(C=0.1), 'est__C': 0.1, 'est__penalty': 'l2'}\n",
      "best score 0.9041292106586225\n",
      "best estimator Pipeline(steps=[('est', LogisticRegression(C=0.1))])\n",
      "best estimator params {'memory': None, 'steps': [('est', LogisticRegression(C=0.1))], 'verbose': False, 'est': LogisticRegression(C=0.1), 'est__C': 0.1, 'est__class_weight': None, 'est__dual': False, 'est__fit_intercept': True, 'est__intercept_scaling': 1, 'est__l1_ratio': None, 'est__max_iter': 100, 'est__multi_class': 'auto', 'est__n_jobs': None, 'est__penalty': 'l2', 'est__random_state': None, 'est__solver': 'lbfgs', 'est__tol': 0.0001, 'est__verbose': 0, 'est__warm_start': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.73864702 0.7976145  0.76425562        nan 0.90412921        nan\n",
      "        nan 0.89471376        nan        nan 0.87858524        nan\n",
      " 0.89036095 0.74074668 0.89700034 0.9037412  0.75019438 0.76648229\n",
      " 0.84497386 0.80622193]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X, y, feature_names = imodels.get_clean_dataset(\"heart\")\n",
    "\n",
    "print(\"shapes\", X.shape, y.shape, \"nunique\", np.unique(y).size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.2\n",
    ")\n",
    "\n",
    "m = imodels.AutoInterpretableClassifier()\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "print(\"best params\", m.est_.best_params_)\n",
    "print(\"best score\", m.est_.best_score_)\n",
    "print(\"best estimator\", m.est_.best_estimator_)\n",
    "print(\"best estimator params\", m.est_.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>param_est</th>\n",
       "      <th>param_est__max_leaf_nodes</th>\n",
       "      <th>param_est__C</th>\n",
       "      <th>param_est__max_rules</th>\n",
       "      <th>param_est__n_estimators</th>\n",
       "      <th>param_est__n_boosting_rounds</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>LogisticRegression(C=0.1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': LogisticRegression(C=0.1), 'est__C': 0.1}</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.011</td>\n",
       "      <td>TreeGAMClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>{'est': TreeGAMClassifier(), 'est__n_boosting_...</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.939</td>\n",
       "      <td>0.055</td>\n",
       "      <td>TreeGAMClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>{'est': TreeGAMClassifier(), 'est__n_boosting_...</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>LogisticRegression(C=0.1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': LogisticRegression(C=0.1), 'est__C': 1}</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>LogisticRegression(C=0.1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': LogisticRegression(C=0.1), 'est__C': 10}</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.015</td>\n",
       "      <td>RuleFitClassifier(max_rules=30)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': RuleFitClassifier(max_rules=30), 'est_...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.001</td>\n",
       "      <td>FIGSClassifier(max_rules=12)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': FIGSClassifier(max_rules=12), 'est__ma...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.001</td>\n",
       "      <td>FIGSClassifier(max_rules=12)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': FIGSClassifier(max_rules=12), 'est__ma...</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': DecisionTreeClassifier(), 'est__max_le...</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.769</td>\n",
       "      <td>3.917</td>\n",
       "      <td>0.087</td>\n",
       "      <td>RuleFitClassifier(max_rules=30)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': RuleFitClassifier(max_rules=30), 'est_...</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': DecisionTreeClassifier(), 'est__max_le...</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>HSTreeClassifier(est=DecisionTreeClassifier(ma...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': HSTreeClassifier(est=DecisionTreeClass...</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>HSTreeClassifier(est=DecisionTreeClassifier(ma...</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': HSTreeClassifier(est=DecisionTreeClass...</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'est': DecisionTreeClassifier(), 'est__max_le...</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  mean_fit_time  mean_score_time  \\\n",
       "3                 1            0.904          0.002            0.001   \n",
       "8                 2            0.902          0.126            0.011   \n",
       "9                 3            0.895          1.939            0.055   \n",
       "4                 4            0.895          0.003            0.001   \n",
       "5                 5            0.879          0.003            0.001   \n",
       "6                 6            0.877          0.371            0.015   \n",
       "12                7            0.845          0.013            0.001   \n",
       "13                8            0.806          0.032            0.001   \n",
       "1                 9            0.798          0.001            0.001   \n",
       "7                10            0.769          3.917            0.087   \n",
       "2                11            0.758          0.001            0.001   \n",
       "10               12            0.751          0.001            0.001   \n",
       "11               13            0.747          0.001            0.001   \n",
       "0                14            0.739          0.001            0.001   \n",
       "\n",
       "                                            param_est  \\\n",
       "3                           LogisticRegression(C=0.1)   \n",
       "8                                 TreeGAMClassifier()   \n",
       "9                                 TreeGAMClassifier()   \n",
       "4                           LogisticRegression(C=0.1)   \n",
       "5                           LogisticRegression(C=0.1)   \n",
       "6                     RuleFitClassifier(max_rules=30)   \n",
       "12                       FIGSClassifier(max_rules=12)   \n",
       "13                       FIGSClassifier(max_rules=12)   \n",
       "1                            DecisionTreeClassifier()   \n",
       "7                     RuleFitClassifier(max_rules=30)   \n",
       "2                            DecisionTreeClassifier()   \n",
       "10  HSTreeClassifier(est=DecisionTreeClassifier(ma...   \n",
       "11  HSTreeClassifier(est=DecisionTreeClassifier(ma...   \n",
       "0                            DecisionTreeClassifier()   \n",
       "\n",
       "   param_est__max_leaf_nodes param_est__C param_est__max_rules  \\\n",
       "3                        NaN          0.1                  NaN   \n",
       "8                        NaN          NaN                  NaN   \n",
       "9                        NaN          NaN                  NaN   \n",
       "4                        NaN            1                  NaN   \n",
       "5                        NaN           10                  NaN   \n",
       "6                        NaN          NaN                   10   \n",
       "12                       NaN          NaN                    5   \n",
       "13                       NaN          NaN                   10   \n",
       "1                          5          NaN                  NaN   \n",
       "7                        NaN          NaN                  100   \n",
       "2                         10          NaN                  NaN   \n",
       "10                         5          NaN                  NaN   \n",
       "11                        10          NaN                  NaN   \n",
       "0                          2          NaN                  NaN   \n",
       "\n",
       "   param_est__n_estimators param_est__n_boosting_rounds  \\\n",
       "3                      NaN                          NaN   \n",
       "8                      NaN                           10   \n",
       "9                      NaN                          100   \n",
       "4                      NaN                          NaN   \n",
       "5                      NaN                          NaN   \n",
       "6                       20                          NaN   \n",
       "12                     NaN                          NaN   \n",
       "13                     NaN                          NaN   \n",
       "1                      NaN                          NaN   \n",
       "7                       20                          NaN   \n",
       "2                      NaN                          NaN   \n",
       "10                     NaN                          NaN   \n",
       "11                     NaN                          NaN   \n",
       "0                      NaN                          NaN   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "3   {'est': LogisticRegression(C=0.1), 'est__C': 0.1}              0.871   \n",
       "8   {'est': TreeGAMClassifier(), 'est__n_boosting_...              0.885   \n",
       "9   {'est': TreeGAMClassifier(), 'est__n_boosting_...              0.868   \n",
       "4     {'est': LogisticRegression(C=0.1), 'est__C': 1}              0.858   \n",
       "5    {'est': LogisticRegression(C=0.1), 'est__C': 10}              0.852   \n",
       "6   {'est': RuleFitClassifier(max_rules=30), 'est_...              0.825   \n",
       "12  {'est': FIGSClassifier(max_rules=12), 'est__ma...              0.792   \n",
       "13  {'est': FIGSClassifier(max_rules=12), 'est__ma...              0.760   \n",
       "1   {'est': DecisionTreeClassifier(), 'est__max_le...              0.708   \n",
       "7   {'est': RuleFitClassifier(max_rules=30), 'est_...              0.879   \n",
       "2   {'est': DecisionTreeClassifier(), 'est__max_le...              0.731   \n",
       "10  {'est': HSTreeClassifier(est=DecisionTreeClass...              0.689   \n",
       "11  {'est': HSTreeClassifier(est=DecisionTreeClass...              0.678   \n",
       "0   {'est': DecisionTreeClassifier(), 'est__max_le...              0.788   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  split4_test_score  \n",
       "3               0.880              0.971              0.917              0.882  \n",
       "8               0.880              0.951              0.910              0.884  \n",
       "9               0.894              0.942              0.905              0.866  \n",
       "4               0.878              0.958              0.900              0.880  \n",
       "5               0.873              0.938              0.855              0.875  \n",
       "6               0.857              0.962              0.880              0.860  \n",
       "12              0.868              0.954              0.833              0.778  \n",
       "13              0.716              0.950              0.850              0.755  \n",
       "1               0.821              0.919              0.800              0.740  \n",
       "7               0.667              0.909              0.730              0.662  \n",
       "2               0.669              0.899              0.757              0.733  \n",
       "10              0.709              0.867              0.773              0.720  \n",
       "11              0.718              0.853              0.764              0.720  \n",
       "0               0.671              0.872              0.724              0.639  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(m.est_.cv_results_).sort_values(\"rank_test_score\")\n",
    "first_cols = [\"rank_test_score\", \"mean_test_score\", \"std_test_score\"]\n",
    "df = df[first_cols + [c for c in df.columns if c not in first_cols]].round(3)\n",
    "# remove std_ cols\n",
    "df = df[[c for c in df.columns if \"std_\" not in c]]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,../imodels/tests/notebooks//py:percent"
  },
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
